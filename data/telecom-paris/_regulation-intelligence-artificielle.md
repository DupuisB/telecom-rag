# Title: Ideas - Comment réguler l'intelligence artificielle ?

## [Accueil](https://www.telecom-paris.fr "https://www.telecom-paris.fr") > [fr](https://www.telecom-paris.fr/fr "fr") > [Ideas](https://www.telecom-paris.fr/fr/ideas "Ideas") > [Comment réguler l’intelligence artificielle ?](https://www.telecom-paris.fr/fr/ideas/regulation-intelligence-artificielle)

[](https://www.telecom-paris.fr/fr/accueil)

# Télécom Paris Ideas  
Comment réguler l'intelligence artificielle ?

## Comment réguler l’intelligence artificielle ?  
Faut-il voir dans l’IA Act un risque de « sur-régulation » ?

[Winston Maxwell](https://www.telecom-paris.fr/winston-maxwell), professeur de
droit à Télécom Paris, février 2024.

Alors que texte final de l’IA Act a été adopté à l’unanimité des 27 pays de
l’UE le 2 février 2024 et que l’adoption par le Parlement européen est
attendue dans les prochaines semaines, Winston Maxwell analyse le compromis
trouvé par l’Europe entre innovation et sécurité mais aussi les questions que
va poser sa mise en œuvre par nos entreprises. L’Europe est-elle devenue la
tête de pont de la régulation de l’IA ?

Winston Maxwell est professeur de droit à Télécom Paris, spécialiste de la
régulation de l’IA (et précédemment avocat aux barreaux de New York et de
Paris).

Propos recueillis par Isabelle Mauriac

## Podcast

Retrouvez cette interview en format audio, enregistrée le 12/12/2023, dans le
cadre des [podcasts Télécom Paris Ideas](https://podcast.ausha.co/telecom-
paris-ideas) :

Podcast Michel Desnoues, Télécom Paris

## Entretien

— Winston, en tant que spécialiste de la question de la régulation de l’IA,
vous avez suivi le long cheminement de l’IA Act avant l’accord intervenu le 2
février 2024. Les discussions sur la régulation des IA génératives ont été
compliquées. Pouvez-vous rappeler les points de tension ?

L’IA Act représente un compromis entre la protection du citoyen et l’objectif
de favoriser l’innovation et l’émergence d’acteurs européens de l’IA. L’IA Act
rentrera en application en 2026, mais qui sait à quoi ressemblera l’IA de 2026
? L’IA évolue tellement vite qu’il existe un réel danger d’obsolescence. En
même temps, l’Europe devait réguler, car elle s’est construite sur le principe
d’une protection élevée des citoyens. De plus, il fallait assurer une
harmonisation à l’échelle européenne pour éviter un morcellement de la
réglementation entre différents pays membres. L’IA Act tente de concilier ces
objectifs.

Dans les négociations finales, la régulation des IA génératives faisait débat.
Le texte consacre finalement un chapitre entier aux modèles à usages multiples
(« general purpose AI »), en régulant plus lourdement les modèles qui
soulèvent des risques systémiques. Dans les débats, le Parlement européen
était particulièrement soucieux des droits fondamentaux qui sont menacés par
les systèmes d’IA. Le Conseil européen lui, était soucieux de l’innovation, du
leadership européen et de la souveraineté numérique. Nécessairement, il y a
une friction entre ces deux visions, car trop de régulation pourrait pénaliser
les acteurs européens.

  * 
Cette friction entre protection et innovation est saine. Il n’y a pas un
modèle qui est préférable à l’autre, les deux doivent coexister.

— Et donc selon vous, est-on arrivé là à un bon compromis pour ne pas trop
brider l’innovation d’un côté, les start-up européennes de la recherche en IA,
et garantir de l’autre côté une régulation suffisante ?

Il est trop tôt pour savoir ! Le nouveau texte compte 85 articles. Ce sera un
règlement tout aussi long et complexe que le RGPD. Il nous faudra plusieurs
années pour comprendre son impact.

La qualité de la régulation dépendra également de l’approche du régulateur de
chaque pays, et comment ce régulateur met en équilibre la protection des
droits des personnes et d’autres objectifs d’intérêt général, la sécurité des
personnes pendant les Jeux Olympiques, pour prendre un exemple.

— L’IA Act régule-t-il la technologie IA, ou bien l’usage qui en est fait?

  * 

À l’origine, l’IA Act se focalisait sur les usages de l’IA, non sur la
technologie en tant que telle.

Donc si on utilise l’IA dans un contexte à haut risque, par exemple pour un
usage de recrutement dans une entreprise, le système sera considéré comme
risqué, soumis à un encadrement strict et l’obligation d’obtenir un marquage «
CE ». Réguler une technologie en tant que telle est plus discutable, surtout
lorsqu’il s’agit de logiciels. Cependant, compte tenu des nouveaux risques des
systèmes d’IA génératives, l’IA Act va imposer à ces outils des obligations de
transparence, et pour certains modèles, des obligations de tests poussées,
quel que soit l’usage qui en est fait en aval.

— De façon plus globale, la régulation de l’IA est aussi au cœur de
l’actualité avec la mise en avant des défaillances de modération de X-Twitter
à l’occasion du conflit israélo-palestinien et de la lenteur des enquêtes et
des sanctions européennes en application du DSA. D’ailleurs, on a parlé d’IA
Act, mais le DSA et le DMA ont été adoptés depuis peu. Avec tout cela, ne
peut-on pas parler de mille-feuilles réglementaire ?

On est en présence d’un système multicouches : Le DSA, le DMA, le RGPD, l’IA
Act, et les règlements sur la cybersécurité, forment un tout, ils
interagissent. On l’oublie souvent, mais le RGPD est déjà un règlement assez
complet et efficace sur les IA, au moins celles qui utilisent des données
personnelles. La CNIL n’a pas attendu l’IA Act pour agir à l’égard des
algorithmes. Le DSA est également un règlement qui vise les algorithmes
utilisés par les grandes plateformes. L’IA Act va simplement compléter les
règlements existants, créant effectivement une couche supplémentaire.

En ce qui concerne la plateforme X-Twitter, le DSA exige la mise en place de
méthodes efficaces, y compris algorithmiques, pour détecter des contenus
illicites. Les algorithmes sont essentiels dans cette lutte. Mais comment
voulez-vous qu’un algorithme fasse le tri entre ce qui est une couverture
journalistique légitime d’un événement horrible, ou une propagande terroriste,
par exemple ? Les algorithmes essaient de faire un premier tri, mais ensuite
ils envoient systématiquement à des modérateurs humains qui doivent décider si
le contenu doit être bloqué.

  * 
Les enjeux sont énormes, surtout à l’approche d’élections. Les algorithmes
sont à la fois un outil redoutable pour propager la désinformation, et un
outil indispensable pour lutter contre cette même désinformation.

— Mais de ce fait, le principal problème est moins l’abondance de
réglementation que les différences selon les zones géographiques : on se
retrouve en face de plateformes, américaines le plus souvent, qui ne se
préoccupent pas forcément des règlements européens ?

L’avantage en Europe est que l’on dispose dorénavant d’une réglementation
unique. Cette réglementation est certes complexe (multicouches), mais au moins
elle est harmonisée. Il y a une vingtaine d’années, il y avait autant de
réglementations qu’il y avait de pays en Europe. Maintenant, avec le RGPD,
avec le DSA et l’IA Act, il y a une seule réglementation européenne. Donc,
l’Europe peut parler d’une seule voix.

Est-ce suffisant pour que les entreprises américaines se plient aux exigences
européennes ? Si l’on s’appuie sur l’expérience du RGPD, la réponse est oui,
mais cela prendra du temps. Les entreprises américaines vont généralement
tester les limites de la réglementation, notamment par des recours en justice.
Il y a toujours une discussion sur la territorialité de la réglementation
européenne. Dans quelle mesure l’IA Act va-t-il s’appliquer à une entreprise
californienne comme Open AI ? Cette discussion aura probablement lieu, mais au
bout de quelques mois ou années, le doute sera levé, et à ce moment-là,
l’ensemble des entreprises, y compris américaines, devront se plier aux
obligations européennes si leurs services sont utilisés en Europe.
Naturellement, pendant cette période d’adaptation, la plupart des entreprises,
y compris américaines, prendront des mesures pour se mettre en conformité avec
l’IA Act, même si par ailleurs elles contestent l’applicabilité de certaines
dispositions.

— Et côté régulation, l’Europe est en avance, mais n’est pas la seule à
prendre des mesures. Les États-Unis ont-ils aussi pris des mesures de
régulation ?

Oui, les États-Unis régulent l’IA, mais d’une autre façon. Récemment la Maison
Blanche a adopté une ordonnance pour pousser le leadership américain en
matière d’IA, tout en protégeant les citoyens contre les abus de l’IA. Le
gouvernement va dédier 2,5 milliards de dollars à la création de bases de
données d’apprentissage et de centres de calcul mutualisés, qui devront être
mis à disposition de chercheurs et d’entreprises innovantes, afin d’encourager
l’innovation. Le gouvernement va essayer d’attirer des talents de l’étranger
en facilitant l’obtention de visa pour les data scientists. L’autorité de la
concurrence américaine lance des enquêtes à l’encontre d’OpenAI, Microsoft,
Google, Amazon et Anthropic, pour s’assurer que l’innovation ne sera pas tuée
dans l’œuf par les GAFAM. Les États fédérés, et même les municipalités,
régulent l’IA. Même si les États-Unis n’adopteront pas un grand « IA Act »
fédéral, il existe une multitude d’actions séparées, une approche pointilliste
de la régulation.

D’ailleurs, on a récemment vu une négociation du syndicat des scénaristes
américains avec Hollywood qui a débouché sur un accord sur l’utilisation de
l’IA générative. Le procès intenté par le New York Times contre Open AI va
également conduire à une forme de régulation de l’IA et du droit d’auteur.

  * 
Sur le fond, Il y a une convergence entre les États-Unis et l’Europe autour
des recommandations de l’OCDE sur l’IA de 2019, qui ont été adoptées par les
deux. La méthode de régulation est différente, mais les objectifs sont les
mêmes.

— Vous parlez des scénaristes et de Hollywood. Il y a une réglementation
nationale, des gardes-fous, puis les applications sectorielles. Au niveau
français, on imagine qu’il y a déjà et qu’il y aura toujours des
réglementations sectorielles ainsi que des régulateurs pour chacun de ces
secteurs ?

Oui, tout à fait. En Europe, il existe de nombreuses réglementations et
régulateurs sectoriels, que ce soit pour la finance, la santé, ou le
transport, qui traitent indirectement déjà de l’IA. L’IA Act va être une forme
de parapluie ou un filet de sécurité, qui va boucher les trous. Mais la
difficulté, c’est qu’il risque d’y avoir des exigences spécifiques, par
exemple en matière de santé, et que ces exigences devront coexister avec la
couche IA Act et la couche RGPD. Ce sera difficile à naviguer au début.

Il y a en ce moment une discussion pour savoir qui sera notre coordinateur «
central » de l’IA en France. La CNIL est en charge de la protection des droits
fondamentaux (et en premier lieu ceux qui ont trait à la vie privée), alors
qu’un régulateur IA devra peser de nombreux intérêts en tension, les droits
fondamentaux, mais aussi des enjeux pour l’innovation, la protection de
l’environnement, la santé publique et la souveraineté numérique.

  * 

Cet équilibrage constitue le défi de la « vision européenne » de l’IA :
centrée sur l’humain mais qui laisse toute sa place à l’innovation et au
progrès scientifique sur le plan mondial.

— Enfin il y a les entreprises qui sont responsables de leur propre
régulation. Nos entreprises françaises et européennes sont-elles prêtes
aujourd’hui à mettre en place une gouvernance de l’IA?

Les entreprises devront mettre en place des systèmes de gouvernance internes
pour les systèmes IA à haut risque. Elles s’inspireront sans doute des
systèmes de gouvernance mis en place pour la RGPD : des contrôles internes,
des audits, des analyses d’impact.

À mon avis, il n’y aura pas de difficulté pour les entreprises à comprendre la
démarche « gouvernance » de l’IA Act. Les banques le font déjà, à chaque fois
qu’elles valident un nouvel algorithme pour un service bancaire, que ce soit
IA ou non. Il y a toute une panoplie d’autorisations internes, de tests, pour
être sûr que le système ne créera pas de risques pour la banque et pour le
système bancaire. Je n’ai aucun souci par rapport à la capacité des grands
groupes, qu’ils soient français ou étrangers, de mettre en place des systèmes
de gouvernance et de gestion de risque conformément à l’IA Act. Ces mesures
font déjà partie de la culture « compliance » des entreprises.

— Les contrôles et les sanctions seront-ils suffisants ?

On a appris avec le RGPD qu’il y a une montée en puissance progressive, qui
s’étale sur plusieurs années. Au début, tout le monde cherche ses marques,
même le régulateur, puis les grosses amendes commencent à tomber, ainsi que
les premières décisions de justice. Et il y aura certainement quelques grands
scandales politiques autour de l’IA, comme l’équivalent de l’affaire Snowden
pour les données personnelles, qui agiront comme un catalyseur afin que le
nouveau système de régulation de l’IA monte en puissance.

[](https://www.telecom-paris.fr/fr/ideas/sommaire)

