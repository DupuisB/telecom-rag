# Title: Ideas - IA générative : empreinte et contribution environnementales du numérique

## [Accueil](https://www.telecom-paris.fr "https://www.telecom-paris.fr") > [fr](https://www.telecom-paris.fr/fr "fr") > [Ideas](https://www.telecom-paris.fr/fr/ideas "Ideas") > [IA générative : empreinte environnementale](https://www.telecom-paris.fr/fr/ideas/ia-generative-empreinte-environnementale)

[](https://www.telecom-paris.fr/fr/accueil)

# Télécom Paris Ideas  
IA générative : empreinte environnementale

## IA générative : empreinte et contribution environnementales du numérique  

[Thomas Le Goff](https://www.telecom-paris.fr/thomas-le-goff), maître de
conférences en droit et régulation du numérique à Télécom Paris, mars 2024.

Thomas Le Goff a participé au rapport de la commission interministérielle sur
l’IA générative, présenté le 13 mars 2024 au Président de la République. Ce
rapport émet 25 propositions pour une stratégie nationale en matière d’IA. La
contribution de Thomas Le Goff porte sur le volet de l’empreinte et de la
contribution environnementales du numérique. Il répond à nos questions.

Propos recueillis par Isabelle Mauriac

## Entretien

— Vous avez contribué aux travaux de la commission interministérielle sur
l’intelligence artificielle générative qui a présenté ses conclusions le 13
mars 2024. Pouvez-vous nous brosser les grands axes de sa réflexion autour de
l’humanisme, de la souveraineté et de la responsabilité ?

La commission interministérielle de l’IA, composé de plusieurs personnalités
reconnues dans le domaine de l’IA, a été établi en septembre 2023 par le
gouvernement afin de rédiger un rapport sur les orientations stratégiques que
devrait prendre la France en matière d’IA, autour de 5 thématiques : impacts
économiques, souveraineté industrielle et économique, éthique et impacts
sociétaux, enjeux culturels et service public.

Dans son
[rapport](https://www.economie.gouv.fr/files/files/directions_services/cge/commission-
IA.pdf), la commission émet 25 recommandations traitant de ces thématiques et
appelle à un grand plan d’investissement à hauteur de 5 milliards d’euros par
an pendant 5 ans.

Dans ses recommandations, la commission appelle à un principe de
responsabilité pour mettre l’innovation au service d’un projet de société et
ne pas « rater le train de l’IA ».

Globalement, on constate que la commission a adopté une posture très pro-
innovation puisqu’il recommande des investissements massifs et l’accélération
de l’adoption dans tous les secteurs, notamment dans les services publics
comme l’éducation ou la santé. Ce qui peut poser des questions puisqu’il
s’agit d’activités essentielles où les risques sont grands et l’on pourrait se
demander s’il est opportun d’aller vers une adoption si massive dans ces
secteurs critiques, sans avoir au préalable identifié et géré tous les risques
que l’IA génère, au risque de tomber dans un « techno-solutionnisme ».  
La commission porte enfin de nombreuses recommandations pour développer le
plein potentiel économique de l’IA (avec une estimation de hausse du PIB entre
250 et 400 milliards d’euros à 10 ans) et garantir la souveraineté de la
France et de l’Europe pour ne pas dépendre de quelques entreprises, a fortiori
extra-européennes.

— Une partie importante de ses travaux est consacré aux intelligences
artificielles génératives. Est-ce sur ces IA que ces enjeux sont les plus
forts ?

Effectivement et c’était d’ailleurs la raison même de l’établissement de la
commission interministérielle.

D’abord, les préoccupations naissent du développement rapide dans le secteur
de l’IA générative, lancé en 2022 avec ChatGpt d’OpenAI, et une multiplication
des modèles disponibles, que ce soit des modèles propriétaires (Microsoft
déploie sa solution Copilot, intégrée à la suite bureautique Office 365, GPT 4
d’OpenAI, Gemini de Google, Claude d’Anthropic…) ou disponibles en open source
(Mistral AI, les modèles Llama de Meta, etc). Il y a donc un fort enjeu de
concurrence, de compétitivité et de souveraineté dans ce secteur en Europe.

Ensuite, des préoccupations voient également le jour en raison des capacités
de ces systèmes. En effet, ces derniers ne sont pas limités qu’à la génération
de textes : on a assisté à l’émergence de systèmes de génération d’images ou
de vidéos, capables de réaliser des Deepfakes très réalistes (on a même
assisté à l’émergence d’une chaine d’information 100% réalisée à partir de
l’IA, avec des faux présentateurs, de faux textes…).

  * 

Contrairement aux systèmes d’IA que l’on connaissait jusqu’à présent, les
systèmes d’IA génératives ne sont pas spécifiques, ils peuvent réaliser un
ensemble de tâches très diverses et être appliqués relativement facilement
dans tous les secteurs d’activités, y compris les plus critiques.

Enfin, certaines caractéristiques intrinsèques de l’IA générative posent
également question : quelles données ont été utilisées pour entraîner les
modèles ? Comment le respect des droits de propriété intellectuelle ou des
données personnelles des personnes a-t-il été assuré ? Comment éviter que la
technologie ne soit utilisée pour générer des fausses informations ou des
deepfakes de personnalités publiques (comme Taylor Swift) ? La diffusion
massive de ces nouveaux systèmes et l’absence de contrôle peuvent ainsi
générer un risque systémique.

— Comment ces travaux s’articulent-ils avec l’IA Act qui a été voté par le
Parlement européen le même jour que la présentation du rapport de la
commission interministérielle ?

Il s’agit de deux sujets distincts.

Le rapport français vise principalement à établir une stratégie française en
matière d’IA générative, à aider le gouvernement dans l’établissement d’une
feuille de route, bien qu’il contienne quelques recommandations portant sur
les risques éthiques et sociétaux. Son contenu est majoritairement dédié aux
aspects économiques, dans une logique pro-innovation, et définit des priorités
d’investissement : le développement des infrastructures de calcul,
l’établissement d’une filière européenne de composants électroniques adaptés à
l’IA, favoriser le déploiement de l’IA dans les services publics, développer
la formation en IA, etc. Les aspects juridiques et les risques éthiques ne
sont, quant à eux, pas très développés (par exemple sur la chaîne de valeur et
les travailleurs du clic…).

À l’inverse, le règlement européen sur l’IA, adopté au Parlement européen le
13 mars 2024 également, vise à construire un cadre européen contraignant
notamment pour (1) interdire les systèmes d’IA générant un risque inacceptable
comme le credit scoring, (2) réguler les systèmes d’IA considérés à haut
risque comme ceux utilisés dans les infrastructures critiques ou la
reconnaissance biométrique, (3) assurer une transparence renforcée pour les
systèmes d’IA présentant un risque moindre. L’IA Act contient des dispositions
spécifiques pour gérer les risques des IA génératives, qui entreraient dans la
qualification de « systèmes d’IA à usage général ». Les fournisseurs de tels
systèmes devront respecter un certain nombre d’obligations pour s’assurer
qu’ils ont été conçus et entraînés dans des conditions qui respectent les
droits d’autrui et assurent un niveau de sécurité approprié. Les systèmes les
plus importants, dits « à risque systémique », seront quant à eux supervisés
directement par les autorités européennes.

— Vous avez contribué pour votre part au chapitre sur l’empreinte carbone du
numérique : « L’IA met-elle en danger notre planète ? ». La frugalité dans
l’IA, rendre les algorithmes moins énergivores… Pour apprendre avec moins de
données, faut-il revisiter les paradigmes du machine learning ?

Effectivement, de nombreuses recherches visent à développer de nouvelles
méthodes d’apprentissage moins énergivores et l’on doit systématiquement se
demander, face à un problème donné, si le machine learning est la technique la
plus adaptée ou si un algorithme d’optimisation classique ne peut pas être
utilisé. Certains de mes collègues ici à Télécom Paris se sont d’ailleurs
spécialisés sur ce sujet.

— Le rapport contient une ambitieuse recommandation sur l’IA et
l’environnement (la n° 5) : « Faire de la France un pionnier de l’IA pour la
planète en renforçant la transparence environnementale, la recherche dans des
modèles à faible impact, et l’utilisation de l’IA au service des transitions
énergétique et environnementales ». Comment la mettre en œuvre ?

La recommandation de la commission interministérielle, qui s’accompagne d’un
plan d’investissement à hauteur de 100 millions d’euros sur 5 ans, est très
proche de celle que j’ai moi-même formulée dans la contribution que je lui ai
soumise en décembre dernier : « Engager la France dans une posture de leader
en matière d’éthique environnementale de l’IA, en promouvant le
développement de technologies limitant leur impact sur la planète tout en
favorisant les cas d’usage contribuant aux efforts de lutte contre le
changement climatique ».

Dans ma contribution, je décline cet objectif ambitieux en 12 recommandations
concrètes. Pour en résumé l’essentiel, je pense que la première étape est
d’avancer sur la standardisation de la mesure de l’empreinte environnementale
des systèmes d’IA et sur la transparence : nous devons nous mettre d’accord
sur ce qui est mesuré, comment on le mesure et, une fois mesuré, le rendre
disponible aux institutions et à la société par la diffusion de données
fiables. Des travaux sont en cours actuellement au niveau européen (CEN-
CENELEC) et à l’ISO (Organisation internationale de normalisation) pour le
développement de normes sur le sujet.

  * 

Sans attendre, l’établissement de bonnes pratiques pour l’écoconception de
systèmes d’IA et la formation des parties prenantes sur le sujet sont
primordiales.

Ensuite, la réponse à la recommandation de la commission IA passera également
par le financement de la recherche en lançant des appels à projets ou en
fléchant des investissements, à la fois vers les recherches sur des modèles à
faible impact environnemental mais aussi et surtout sur des projets d’IA
utiles pour atteindre les objectifs de développement durable.

Enfin, une réflexion doit être engagée sur le rôle de la régulation pour
parvenir à une IA neutre en carbone. Faut-il édicter des règles contraignantes
? Quels mécanismes juridiques ou économiques pourraient inciter les acteurs à
adopter un comportement vertueux ? De la même façon que l’AI Act impose aux
fournisseurs d’IA à haut risque de réaliser une analyse d’impact sur les
droits fondamentaux, ne faut-il pas imposer à certains acteurs la réalisation
d’étude d’impact environnemental ? Comment mettre en œuvre une forme de «
sustainability by design » (dès la conception) comme le « privacy by design »
?

— Sur ce volet justement, n’est-ce pas dommage que le sujet de la contribution
de l’IA à la lutte contre le dérèglement climatique soit juste évoqué dans le
rapport ?

Il est dit en fin de ce chapitre que l’impact environnemental de l’IA doit
être mis en regard de ses potentiels bénéfices.

C’est effectivement dommage que la question écologique soit juste évoquée
puisqu’il est primordial de mettre en balance les risques environnementaux
liés au fonctionnement de l’IA (émissions de gaz à effet de serre liées à la
consommation énergétique, consommation en eau des data centers, besoin en
matériaux rares…) avec ses potentiels apports pour contribuer aux objectifs de
développement durable.

Par exemple, l’IA a un grand potentiel pour contribuer à la diminution des
émissions de gaz à effet de serre dans de nombreux secteurs. Dans le secteur
de l’énergie par exemple, l’IA peut être utilisée pour faciliter l’intégration
des énergies renouvelables dans le réseau électrique en optimisant la
prévision de leur production, pour optimiser la charge des véhicules
électriques en fonction des contraintes du réseau ou encore en optimisant la
consommation énergétique des bâtiments. Ces effets positifs doivent également
être pris en considération !

  * 
Le rapport conclut que tout dépend de l’utilisation qui est faite : «
L’utilisation des modèles implique une hausse de la consommation énergétique,
même si elle est en partie compensée par les bonds dans leur efficacité
énergétique. Cependant, les modèles d’IA peuvent accélérer l’innovation verte
et ainsi lutter contre le réchauffement climatique ».

## Vidéos

Pour afficher ce contenu, merci d’accepter les cookies des vidéos Youtubedes
extraits de réseaux sociaux (Twitter, Instagram & Facebook).To display this
content, please accept third party cookies for Youtube videosFacebook,
Instagram and Linkedin excerpts.

Réglages

Pour afficher ce contenu, merci d’accepter les cookies des vidéos Youtubedes
extraits de réseaux sociaux (Twitter, Instagram & Facebook).To display this
content, please accept third party cookies for Youtube videosFacebook,
Instagram and Linkedin excerpts.

Réglages

Vidéos Michel Desnoues, Télécom Paris

[](https://www.telecom-paris.fr/fr/ideas/sommaire)

